\documentclass{sig-alternate}
\usepackage{verbatim}
\usepackage{array}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage[table]{xcolor}
\usepackage{xcolor,colortbl}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage{tabularx}

\definecolor{myGray}{gray}{0.8}

%\newcommand\rankeq{\stackrel{\mathclap{\normalfont\mbox{rank}}}{=}}
\newcommand\rankeq{\mathrel{\overset{\makebox[0pt]{\mbox{\normalfont\tiny\sffamily rank}}}{=}}}

\setlist[itemize]{noitemsep}  % remove space between list items

\begin{document}

\numberofauthors{2}

\author{[Blind]}
%\author{
%Garrick Sherman and Miles Efron \\
%     \affaddr{Graduate School of Library and Information Science}\\
%       \affaddr{University of Illinois at Urbana-Champaign}\\
%       \email{\{gsherma2, mefron\}@illinois.edu}
%}
\conferenceinfo{SIGIR}{2016 Pisa, Italy}

\title{Document knowledge base linking for information retrieval}

\maketitle
\begin{abstract}
Entity linking and wikification are the tasks of matching mentions of an entity, such as a person, place, or organization, or a concept with its representation in a knowledge base such as Wikipedia. While there has been some investigation into use of entity linking in information retrieval, its usage may be hampered by the computational expense of constructing accurate entity annotations on large corpora, the frequent need for training data to construct entity links, and the ambiguity involved in real-world entity linking. We present a method by which a ``bag of links'' from a document to a knowledge base may be generated using standard information retrieval techniques with Wikipedia. We also suggest a document expansion approach that employs these links, which is effective in improving retrieval results.
\end{abstract}

% A category with the (minimum) three required fields
\category{H.3.3}{Information Search and Retrieval}{}

%\terms{}
%\keywords{Entity linking}

\section{Introduction}\label{section.intro}

Entity linking and wikification have been the subject of much research, especially from the Text Analysis Conference (TAC) Knowledge Base Population (KBP) entity linking track. Systems are designed to link mentions of entities or concepts found in the text to their representations in a knowledge base such as Wikipedia\footnote{http://wikipedia.org} or Freebase\footnote{http://freebase.org}.

These links enrich documents by connecting knowledge base information such as hyperlink graphs, entity membership in categories, and additional text to the annotated documents. It seems reasonable that information retrieval (IR) systems might take advantage of this added source of information to improve the quality of search results. Unfortunately, producing high quality entity annotations is often a computationally expensive process. In addition, these systems generally require training data, which increases the barrier to use. Much entity linking and wikification research has also assumed more amenable circumstances that complicate their application to real-world text. For example, until 2014, the KBP entity linking track supplied explicit mention boundaries to participants.

In this paper, we present a method of using standard information retrieval techniques to produce knowledge base links for a corpus of documents. Our approach benefits by removing the requirement that links connect specific mentions from the text. We argue that such a ``bag of links'' provides many of the same benefits as more fine-grained entity linking or wikification processes for the purposes of ad hoc document retrieval. To demonstrate this benefit, we employ our knowledge base links using a simple document expansion model, which yields improvement over IR baselines.

\section{Related Work}\label{section.related}

\subsection{Entity Linking, Wikification, and Entity Retrieval}\label{section.related.entities}

Entity linking and wikification have been studied extensively, particularly in the context of TAC KBP \cite{Ji2014}. Variations on these tasks exist: in some instances, entity mentions are assumed to be available, essentially reducing the tasks to disambiguation; more recently, the tasks includes identification of mentions in raw document text. If a system must identify entity mentions, it is common to use a named entity recognition tagger \cite{Hoffart2011, Ratinov2011}

Entity linking systems often exploit knowledge base structure to help match and disambiguate entities. For example, Cucerzan \cite{Cucerzan2007} employs Wikipedia disambiguation pages and redirection pages to help identify various entity surface forms. The use of anchor text and hyperlink graphs is also a frequent feature of these systems \cite{Mihalcea2007, Ratinov2011, Stoyanov2012}. Most systems employ some form of context, which often refers to the co-occurrence of entities as evidence for disambiguation \cite{Stoyanov2012, Dalton2013}. Another use of context, relating most closely to our approach in this paper, refers the text surrounding an entity mention, which can be used to disambiguate knowledge base representations \cite{Mihalcea2007, Dalton2013}.

The related area of entity retrieval is also relevant to our work, e.g. \cite{Adafre2007, Bron2010}. Entity retrieval refers to the task of retrieving entities, rather than documents, in response to a specified information need. This was studied at the TREC entity retrieval track \cite{Balog2011}. Though entity retrieval tasks differ from ours in that entities are explicitly requested by the user, the querying of a corpus to retrieve entities is conceptually similar to much of our knowledge base linking approach.

\subsection{Document Expansion in Information Retrieval}\label{section.related.ir}

Investigation into the use of knowledge base links for document retrieval have, to our knowledge, been limited. Those applications most similar to ours use entity links in a feedback process to expand queries. Dalton and Dietz \cite{Dalton2014} use a number of sources, including entity-annotated queries and pseudo-relevance feedback (PRF) on entity-annotated document collections. Their process is underpinned by entity links produced by their KB Bridge system \cite{Dalton2013}. Similarly, Xiong and Callan expand queries using PRF with the descriptions and categories of Freebase objects linked to a retrieved document in the FACC1\footnote{http://lemurproject.org/clueweb09/FACC1/} annotation data. They employ a supervised machine learning model to select expansion terms, trained on the basis of the terms' influence on the ranking scores of relevant documents \cite{Xiong2015}.

In contrast, our approach is concerned with \textit{document} expansion. It is based on two-stage smoothing \cite{Zhai2004}; however, while two-stage smoothing generally uses the collection as its background language model, we introduce the knowledge base description text. Our idea is closely related to Wei and Croft's LDA-based document model, which smooths the document language model with latent Dirichlet allocation probabilities \cite{Wei2006}. Liu and Croft's \textit{CBDM} model performs a similar type of smoothing by interoplating the probability of a query term in a document cluster with its probability in the document \cite{Liu2004}.

\section{Constructing Knowledge Base Links}\label{section.linking}

\subsection{Underlying Retrieval Model}\label{section.linking.model}
Throughout this paper we rely on the language modeling retrieval framework \cite{Lafferty2001}, though this is not strictly necessary and imposes no particular mathematical constraints on our approach.

More specifically, our framework for all of the retrievals carried out in this work is the query likelihood (QL) ranking method.  Given a query $Q$ and a document $D$, we rank documents on $P(Q | \theta_D)$, where $\theta_D$ is the language model (typically a multinomial over the vocabulary $V$) that generated the text of document $D$.  Assuming independence among terms and a uniform distribution over documents, each document is scored by

\begin{flalign}\label{equation.ql}
\log P(Q | D) = \prod_{w \in Q} P(w | Q) \cdot \log P(w | \theta_D) .
\end{flalign}

\noindent We follow standard procedures for estimating the probabilities in Eq. \ref{equation.ql}.  We simply use the maximum likelihood estimate of $\hat{P}(w | Q) = \frac{c(w, Q)}{|Q|}$ where $c(w, Q)$ is the frequency of word $w$ in $Q$.  For $P(w | \theta_D)$ we estimate a smoothed language model by assuming that document language models
in a given collection have a Dirichlet prior distribution:

\begin{flalign}\label{equation.ql}
\hat{P}(w | \theta_D) = \frac{c(w, D) + \mu \hat{P}(w | C)}{|D| + \mu} 
\end{flalign}

\noindent where $\hat{P}(w | C)$ is the maximum likelihood estimate of the probability of seeing word $w$ in a ``background" collection $C$ (typically $C$ is the corpus from which $D$ is drawn), and $\mu \geq 0$ is the smoothing hyper-parameter. 


\subsection{Linking with Document Pseudo-Queries}\label{section.linking.queries}
%The KL-divergence retrieval model measures the distance between the query language model, $\theta_{D_Q}$ here, and the document language model, $\theta_E$, as follows:
%
%\begin{flalign*}
%	score(E,D_Q) 	&= -KL(\theta_{D_Q}||\theta_E) \\
%					&\rankeq \sum_{w \in V} P(w|\theta_{D_Q}) \log P(w|\theta_E)
%&\end{flalign*}
%
\noindent To find candidate entities to ``link" to a given document $D$, we begin by treating the text of $D$ as a pseudo-query which we pose against a collection of entities $C_E$.  To transform a document into a pseudo-query we apply two transformations.  First we remove all terms from $D$ that appear in the standard Indri stoplist\footnote{http://www.lemurpro ject.org/stopwords/stoplist.dft}.  Next, we prune our pseudo-query by retaining only the $0 < k \leq |D|$ most frequent words in the stemmed text of $D$.  The integer variable $k$ is a parameter that we choose empirically.  Let $Q_D$ be the pseudo-query for $D$, consisting of the text of $D$ after our two transformations.

With our pseudo-query for document $D$ in hand, we obtain a list of candidate entities by running $Q_D$ over an index of our knowledge base, $C_E$, where each entry in this index is the text of an entity $E$'s knowledge base node. More formally, we rank the entities in our knowledge base against $D$ using Eq. \ref{equation.ql}, substituting $D_Q$ for the query and $E_i$--the text of the $i^{th}$ entity--for the document. Let $\pi_i$ be the log-probability for entity $E_i$ with respect to $D$ given by equation \ref{equation.ql}.  

We now have a ranked list of tuples $\{(E_1, \pi_1)$, $(E_2, \pi_2)$, $...$, $(E_N, \pi_N)\}$ relating knowledge base entry $E_i$ to $D$ with log-probability $\pi_i$. Our final step is to take the top $n$ entries where $0 \leq n \leq N$. We call these top entries $\mathcal{E}_D$ and designate them as our knowledge base links for $D$.  Finally, we exponentiate each $\pi_i$ and normalize our entity scores so they sum to 1 over the $n$ retained entities.  Assuming a uniform prior over entities, we now have a probability distribution over our $n$ retained entities: $P(E | D)$.

Since this procedure does not depend on the query, we may compute $\mathcal{E}_D$ once at indexing time and reuse our knowledge base links across queries. 

\section{KB-Linked Retrieval Model}\label{section.model}

We would now like to incorporate our knowledge base links into a retrieval model over documents. Though many knowledge bases provide structured information such as hyperlink graphs and entity category information, in this work we focus only on the textual content supplied for each entry.

We assume that a query is generated by a mixture of the document model $\theta_D$ and a model $\theta_K$ representing the concepts linked from the knowledge base. We assume that $\theta_K$ can be estimated using the linked knowledge base concepts $\mathcal{E}_D$. This mixture model may be expressed as:
%
\begin{flalign}\label{eq.ql-and-entities}
	\hat{P}^\lambda(Q|D) &= \prod_{i=1}^m (1-\lambda) P(q_i|D) + \lambda P(q_i|\mathcal{E}_D)
\end{flalign}

\noindent The larger $\lambda$ is, the more we believe that the knowledge base concepts are responsible for generating $Q$, and the less we believe that the document is responsible for generating $Q$. We estimate $P(q_i|\mathcal{E}_D)$ in expectation:
%
\begin{flalign}\label{eq.entity-sum}
	P(q_i|\mathcal{E}_D) &= \sum_{E \in \mathcal{E}_D} P(q_i|E) P(E|D) .
\end{flalign}

\noindent Like $P(q_i|D)$, we estimate $P(q_i|E)$ as a Dirichlet-smoothed query likelihood, but using the knowledge base's text for entry $E$ to estimate of the underlying model. By virtue of our entity-document scoring and normalization, we also have $P(E|D)$.

\section{Evaluation}\label{section.evaluation}

\subsection{Data}\label{section.evaluation.collections}

To perform knowledge base linking, we make use of the September 1, 2015 dump of English Wikipedia. We build an Indri\footnote{http://www.lemurproject.org/indri/} index over the Wikipedia page text. The text of each Wikipedia page also serves as the ``description text'' used in Eq. \ref{eq.entity-sum}.

We test our approach using the TREC 2004 robust topics. These 250 topics are used with data from TREC disks 4 and 5. In addition, we use the AP newswire collection from TREC disks 1 and 2 with topics 101-200. % needs work

\subsection{Runs}\label{section.evaluation.runs}

%In some of the following runs, we make use of the RM3 variant of relevance modeling \cite{Lavrenko2001} which interpolates the original query $Q$ with the relevance model using a mixing parameter $\alpha$. RM3 provides a stronger baseline than standard query likelihood.

We produce two runs per collection:
\begin{itemize}
	\item \textit{baseline-ql}, a baseline query likelihood run
%	\item \textit{baseline-rm3}, a baseline RM3 run
	\item \textit{kb-ql}, incorporating knowledge base links using Eq \ref{eq.ql-and-entities}.
%	\item \textit{kb-rm3}, incorporating knowledge base links using an initial RM3 retrieval
\end{itemize}

For the two \textit{kb} runs, we retrieve the top 1000 documents per query based on the default Indri query likelihood implementation. We then re-rank these documents by incorporating their knowledge base links as described in Section \ref{section.model}. 

\subsection{Parameters}\label{section.evaluation.parameters}

\begin{table}[htbp]
\centering
\begin{tabular}{|c|p{0.28\textwidth}|c|} \hline
{\bf Param} & {\bf Meaning} & {\bf Value} \\ \hline
$k$ & The maximum number of document terms to use in constructing $D_Q$. & 20 \\ \hline
$n$ & The maximum number of knowledge base entries in $\mathcal{E}_D$. & 10 \\ \hline
$\lambda$ & Mixing parameter controlling the weights of $P(q|D)$ and $P(q|E)$ & 0.0-1.0 \\ \hline
$\mu$ & Used for Dirichlet smoothing of both $P(q|D)$ and $P(q|E)$. & 2500 \\ \hline
%$fbDocs$ & The number of feedback documents to use for RM3 runs. & 20 \\ \hline
%$fbTerms$ & The number of terms per document to use for RM3 runs. & 20 \\ \hline
%$\alpha$ & Mixing parameter controlling the weights of the original query and relevance model for RM3 runs. & 0.5 \\ \hline
\end{tabular}
\caption{Parameter settings for the entity linking procedure and retrieval model}
\label{table.parameters}
\end{table}

The various parameters required for our approach, along with their meanings and values are shown in Table \ref{table.parameters}. 

We sweep across values of $\lambda$ at intervals of $0.1$ to investigate how much weight should be given to the entity model. The results of these sweeps are shown in Figure \ref{figure.sweeps-ql} and discussed further in Section \ref{section.results}.

For this work, we set $k$ and $n$ heuristically. In principle, both parameters need not be limited beyond the length of the document and size of the corpus respectively; however, this would increase computation time significantly, so we have opted to set them to the specified values.

\section{Results}\label{section.results}

\begin{table}[htbp]
\centering
\begin{tabular}{|c|l|c|c|} \hline
& {\bf Run} & {\bf $\lambda$} & {\bf MAP} \\ \hline
\multirow{2}{*}{Robust} & {\it baseline-ql} & -- & 0.2183 \\ \cline{2-4}
%& {\it baseline-rm3} & -- & 0.2548 \\ \cline{2-4}
& {\it kb-ql} & 0.9 & {\bf 0.2275} \\ \hline \hline %\cline{2-4}
%& {\it kb-rm3} & & \\ \hline \hline
\multirow{2}{*}{AP} & {\it baseline-ql} & -- & 0.2346 \\ \cline{2-4}
%& {\it baseline-rm3} & -- & 0.2653 \\ \cline{2-4}
& {\it kb-ql} & 0.9 & {\bf 0.2515} \\ \hline %\cline{2-4}
%& {\it kb-rm3} & 0.8 & 0.2665 \\ \hline
\end{tabular}
\caption{The top-scoring knowledge base runs and baselines by mean average precision (MAP). $\lambda$ is specified for knowledge base runs. Bolded values indicate statistical significance compared to the baseline.}
\label{table.performance}
\end{table}

\begin{figure}
\centering
\includegraphics[width=\columnwidth]{figures/sweep-ql.pdf}
\caption{Sweeps over values of $\lambda$ for robust (red) and AP (blue) runs.}
\label{figure.sweeps-ql}
\end{figure}

\begin{comment}
\begin{figure}
\centering
\includegraphics[width=\columnwidth]{figures/sweep-rm3.pdf}
\caption{Sweeps over values of $\lambda$ for robust (red) and AP (blue) RM3 runs.}
\label{figure.sweeps-rm3}
\end{figure}
\end{comment}

Retrieval performance of the top-scoring knowledge base runs and baselines are shown in Table \ref{table.performance}. Bolded mean average precision (MAP) scores are greater than their corresponding baseline (e.g. \textit{kb-ql} compared to \textit{baseline-ql}) with statistical significance at $p < 0.001$ using a paired t-test. Note that baselines correspond to $\lambda = 0.0$. 

Though Table \ref{table.performance} shows only the top-scoring values of $\lambda$, performance for all knowledge base runs improved over the baseline for values of $0.0 < \lambda < 1.0$, as shown in Figure \ref{figure.sweeps-ql}. All improvements were statistically significant with at least $p < 0.05$.

% Paragraph about RM3 results...

\section{Conclusions}\label{section.conclusions}

The results indicate that our approach for constructing knowledge base links between documents and Wikipedia produces useful data for document retrieval purposes. Our simple document expansion model that incorporates these links performs well compared to a query likelihood baseline. These outcomes support our argument that a ``bag of links'' to a knowledge base can provide helpful information for a document retrieval task. Our proposed method using standard information retrieval techniques to build these links is efficient compared to usual entity linking and wikification systems and can be accomplished without the need for complex natural language processing.

In this paper, we have limited ourselves to using only knowledge base description text. However, knowledge base links provide a great deal more information. Future work may benefit from harnessing this knowledge base data such as hyperlink graphs and entity categories. Since our retrieval model performs \textit{document} expansion, we also plan to investigate its utility when paired with \textit{query} expansion techniques that employ knowledge base links.

\section{Acknowledgments}\label{section.acknowledgments}
This work was supported in part by the US National Science Foundation under Grant No. [blind]. Any opinions, findings, conclusions, or recommendations expressed are those of the authors and do not necessarily reflect the views of the National Science Foundation.


\bibliographystyle{abbrv}
\bibliography{references}  




\end{document}
