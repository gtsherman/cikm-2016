\documentclass{sig-alternate}
\usepackage{verbatim}
\usepackage{array}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage[table]{xcolor}
\usepackage{xcolor,colortbl}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage{tabularx}

\definecolor{myGray}{gray}{0.8}

%\newcommand\rankeq{\stackrel{\mathclap{\normalfont\mbox{rank}}}{=}}
\newcommand\rankeq{\mathrel{\overset{\makebox[0pt]{\mbox{\normalfont\tiny\sffamily rank}}}{=}}}

\setlist[itemize]{noitemsep}  % remove space between list items

\begin{document}

\numberofauthors{2}

\author{[Blind]}
%\author{
%Garrick Sherman and Miles Efron \\
%     \affaddr{Graduate School of Library and Information Science}\\
%       \affaddr{University of Illinois at Urbana-Champaign}\\
%       \email{\{gsherma2, mefron\}@illinois.edu}
%}
\conferenceinfo{SIGIR}{2016 Pisa, Italy}

\title{Document knowledge base linking for information retrieval}

\maketitle
\begin{abstract}
Entity linking and wikification are the tasks of matching mentions of an entity, such as a person, place, or organization, or a concept with its representation in a knowledge base such as Wikipedia. While there has been some investigation into use of entity linking in information retrieval, its usage may be hampered by the computational expense of constructing accurate entity annotations on large corpora, the frequent need for training data to construct entity links, and the ambiguity involved in real-world entity linking. We present a method by which a ``bag of links'' from a document to a knowledge base may be generated using standard information retrieval techniques with Wikipedia. We also suggest a document expansion approach that employs these links, which is effective in improving retrieval results.
\end{abstract}

% A category with the (minimum) three required fields
\category{H.3.3}{Information Search and Retrieval}{}

%\terms{}
%\keywords{Entity linking}

\section{Introduction}\label{section.intro}

Entity linking and wikification have been the subject of much research, especially from the Text Analysis Conference (TAC) Knowledge Base Population (KBP) entity linking track. Systems are designed to link mentions of entities or concepts found in the text to their representations in a knowledge base such as Wikipedia\footnote{http://wikipedia.org} or Freebase\footnote{http://freebase.org}.

These links enrich documents by connecting knowledge base information such as hyperlink graphs, entity membership in categories, and additional text to the annotated documents. It seems reasonable that information retrieval (IR) systems might take advantage of this added source of information to improve the quality of search results. Unfortunately, producing high quality entity annotations is often a computationally expensive process. In addition, these systems generally require training data, which increases the barrier to use. Much entity linking and wikification research has also assumed more amenable circumstances that complicate their application to real-world text. For example, until 2014, the KBP entity linking track supplied explicit mention boundaries to participants.

In this paper, we present a method of using standard information retrieval techniques to produce knowledge base links for a corpus of documents. Our approach benefits by removing the requirement that links connect specific mentions from the text. We argue that such a ``bag of links'' provides many of the same benefits as more fine-grained entity linking or wikification processes for the purposes of ad hoc document retrieval. To demonstrate this benefit, we employ our knowledge base links using a simple document expansion model, which yields improvement over IR baselines.

\section{Related Work}\label{section.related}

\subsection{Entity Linking, Wikification, and Entity Retrieval}\label{section.related.entities}

Entity linking and wikification have been studied extensively, particularly in the context of TAC KBP \cite{Ji2014}. Variations on these tasks exist: in some instances, entity mentions are assumed to be available, essentially reducing the tasks to disambiguation; more recently, the tasks includes identification of mentions in raw document text. If a system must identify entity mentions, it is common to use a named entity recognition tagger \cite{Hoffart2011, Ratinov2011}

Entity linking systems often exploit knowledge base structure to help match and disambiguate entities. For example, Cucerzan \cite{Cucerzan2007} employs Wikipedia disambiguation pages and redirection pages to help identify various entity surface forms. The use of anchor text and hyperlink graphs is also a frequent feature of these systems \cite{Mihalcea2007, Ratinov2011, Stoyanov2012}. Most systems employ some form of context, which often refers to the co-occurrence of entities as evidence for disambiguation \cite{Stoyanov2012, Dalton2013}. Another use of context, relating most closely to our approach in this paper, refers the text surrounding an entity mention, which can be used to disambiguate knowledge base representations \cite{Mihalcea2007, Dalton2013}.

The related area of entity retrieval is also relevant to our work, e.g. \cite{Adafre2007, Bron2010}. Entity retrieval refers to the task of retrieving entities, rather than documents, in response to a specified information need. This was studied at the TREC entity retrieval track \cite{Balog2011}. Though entity retrieval tasks differ from ours in that entities are explicitly requested by the user, the querying of a corpus to retrieve entities is conceptually similar to much of our knowledge base linking approach.

\subsection{Document Expansion in Information Retrieval}\label{section.related.ir}

Investigation into the use of knowledge base links for document retrieval have, to our knowledge, been limited. Those applications most similar to ours use entity links in a feedback process to expand queries. Dalton and Dietz \cite{Dalton2014} use a number of sources, including entity-annotated queries and pseudo-relevance feedback (PRF) on entity-annotated document collections. Their process is underpinned by entity links produced by their KB Bridge system \cite{Dalton2013}. Similarly, Xiong and Callan expand queries using PRF with the descriptions and categories of Freebase objects linked to a retrieved document in the FACC1\footnote{http://lemurproject.org/clueweb09/FACC1/} annotation data. They employ a supervised machine learning model to select expansion terms, trained on the basis of the terms' influence on the ranking scores of relevant documents \cite{Xiong2015}.

In contrast, our approach is concerned with \textit{document} expansion. It is based on two-stage smoothing \cite{Zhai2004}; however, while two-stage smoothing generally uses the collection as its background language model, we introduce the knowledge base description text. Our idea is closely related to Wei and Croft's LDA-based document model, which smooths the document language model with latent Dirichlet allocation probabilities \cite{Wei2006}. Liu and Croft's \textit{CBDM} model performs a similar type of smoothing by interoplating the probability of a query term in a document cluster with its probability in the document \cite{Liu2004}.

\section{Constructing Knowledge Base Links}\label{section.linking}

Unlike most entity linking and wikification tasks, ours does not require the identification of entity or concept mentions in the document text. Instead, we are satisfied with a ``bag of links'' between a document and the knowledge base. These links provide the same benefits for our retrieval task as those that refer to specific mentions. Further, this choice frees our approach to use standard information retrieval techniques in a straightforward way. This allows us to construct links more efficiently than typical wikification systems and without the need for training data, instead using a standard inverted index over a knowledge base corpus. 

In the following, we differentiate between the target corpus, $C_T$, from which the user would like to retrieve a document, and the knowledge base corpus, $C_K$, which is used for the entity linking procedure. 

For a given document $D$ in $C_T$, our task is to construct a set of knowledge base links. The essence of our approach is to use $D$ as a query against $C_K$; the result of this query is a set of knowledge base entries with retrieval scores. 

First, we remove stop words from $D$ using Indri's standard stop list\footnote{http://www.lemurproject.org/stopwords/stoplist.dft}. We then prune the document to include only the top $k$ terms, with $0 < k \leq |D|$ where $|D|$ is the length of the stopped document. Call this pruned document $D_Q$. We may now issue $D_Q$ as a query against $C_K$ using the KL-divergence retrieval model \cite{Lafferty2001}. The KL-divergence retrieval model measures the distance between the query language model, $\theta_{D_Q}$ here, and the document language model, $\theta_E$, as follows:
%
\begin{flalign*}
	score(E,D_Q) 	&= -KL(\theta_{D_Q}||\theta_E) \\
					&\rankeq \sum_{w \in V} P(w|\theta_{D_Q}) \log P(w|\theta_E)
\end{flalign*}
%
where $E$ is a candidate entity and $w$ is a word in the vocabulary $V$.

This results in a ranked list of tuples $\{(E_1, S_1)$, $(E_2, S_2)$, $...$, $(E_N, S_N)\}$ relating knowledge base entry $E_i$ to $D$ with probability $S_i$. Our final step is to take the top $n$ entries where $0 \leq n \leq N$. We call these top entries $\mathcal{E}_D$ and designate them as our knowledge base links for $D$. 

Note that, since this procedure does not depend on the query, we may compute $\mathcal{E}_D$ once at indexing time and reuse our knowledge base links across queries. 

\section{KB-Linked Retrieval Model}\label{section.model}

We would now like to incorporate our knowledge base links into a retrieval model. Though the knowledge base provides more structured information such as hyperlink graphs and entity category information, in this work we choose to focus on the description text supplied for each entry.

%We take a language modeling approach to retrieval. A major problem of language modeling is the sparseness of observations from the document language model $\theta_D$ \cite{}. One common solution to this problem is to smooth a document using a background language model based on the collection. These background probabilities help to ensure...

In the query likelihood retrieval model, we rank documents by the probability that their underlying distribution over words, $\theta_D$, would generate the query $Q$. Using the maximum likelihood estimate of $\theta_D$ based on $D$ and Bayes' rule, we have:
%
\begin{flalign}\label{eq.lm}
	P(D|Q) 	&= \frac{P(Q|D)P(D)}{P(Q)} \\
			&\rankeq P(Q|D)P(D)
\end{flalign}

Often, as we do in this paper, $P(D)$ is assumed to be uniform and may be ignored. With Dirichlet smoothing, we compute $P(Q|D)$ as follows:
%
\begin{flalign}\label{eq.ql}
	P(Q|D) 	&= \prod_{i=1}^m P(q_i|D) \\
			&= \prod_{i=1}^m \frac{c(q_i,D) + \mu P(q_i|C)}{|D| + \mu}
\end{flalign}
%
where $c(q_i,D)$ is the count of query term $q_i$ in the document, $P(q_i|C)$ is the term's background probability in the collection $C$, and $\mu$ is a parameter.

We assume that a query is generated by mixing the document model $\theta_D$ with a model $\theta_K$ representing the concepts linked from the knowledge base. We assume that $\theta_K$ can be estimated using the linked knowledge base concepts $\mathcal{E}_D$. This mixture model may be expressed as:
%
\begin{flalign}\label{eq.ql-and-entities}
	P(Q|D) &= \prod_{i=1}^m (1-\lambda) P(q_i|D) + \lambda P(q_i|\mathcal{E}_D)
\end{flalign}

The larger $\lambda$ is, the more we believe that the knowledge base concepts are responsible for generating $Q$, and the less we believe that the document is responsible for generating $Q$. We can estimate $P(q_i|\mathcal{E}_D)$ as follows:
%
\begin{flalign}\label{eq.entity-sum}
	P(q_i|\mathcal{E}_D) &= \sum_{E \in \mathcal{E}_D} P(q_i|E) P(E|D) P(D)
\end{flalign}

Like $P(q_i|D)$, we estimate $P(q_i|E)$ as a Dirichlet smoothed query likelihood, but using the knowledge base's description text for entry $E$ to estimate of the underlying model. We are also already provided estimates of $P(E|D)$ by the linking process: this quantity corresponds to retrieval score $S$ computed for $E$ from Section \ref{section.linking}. As in Eq. \ref{eq.ql}, we assume $P(D)$ to be uniform.

\section{Evaluation}\label{section.evaluation}

\subsection{Data}\label{section.evaluation.collections}

To perform knowledge base linking, we make use of the September 1, 2015 dump of English Wikipedia. We build an Indri\footnote{http://www.lemurproject.org/indri/} index over the Wikipedia page text. The text of each Wikipedia page also serves as the ``description text'' used in Eq. \ref{eq.entity-sum}.

We test our approach using the TREC 2004 robust topics. These 250 topics are used with data from TREC disks 4 and 5. In addition, we use the AP newswire collection from TREC disks 1 and 2 with topics 101-200. % needs work

\subsection{Runs}\label{section.evaluation.runs}

%In some of the following runs, we make use of the RM3 variant of relevance modeling \cite{Lavrenko2001} which interpolates the original query $Q$ with the relevance model using a mixing parameter $\alpha$. RM3 provides a stronger baseline than standard query likelihood.

We produce two runs per collection:
\begin{itemize}
	\item \textit{baseline-ql}, a baseline query likelihood run
%	\item \textit{baseline-rm3}, a baseline RM3 run
	\item \textit{kb-ql}, incorporating knowledge base links using an initial query likelihood retrieval
%	\item \textit{kb-rm3}, incorporating knowledge base links using an initial RM3 retrieval
\end{itemize}

For the two \textit{kb} runs, we retrieve the top 1000 documents per query based on the default Indri query likelihood implementation. We then re-rank these documents by incorporating their knowledge base links as described in Section \ref{section.model}. 

\subsection{Parameters}\label{section.evaluation.parameters}

\begin{table}[htbp]
\centering
\begin{tabular}{|c|p{0.28\textwidth}|c|} \hline
{\bf Param} & {\bf Meaning} & {\bf Value} \\ \hline
$k$ & The maximum number of document terms to use in constructing $D_Q$. & 20 \\ \hline
$n$ & The maximum number of knowledge base entries in $\mathcal{E}_D$. & 10 \\ \hline
$\lambda$ & Mixing parameter controlling the weights of $P(q|D)$ and $P(q|E)$ & 0.0-1.0 \\ \hline
$\mu$ & Used for Dirichlet smoothing of both $P(q|D)$ and $P(q|E)$. & 2500 \\ \hline
%$fbDocs$ & The number of feedback documents to use for RM3 runs. & 20 \\ \hline
%$fbTerms$ & The number of terms per document to use for RM3 runs. & 20 \\ \hline
%$\alpha$ & Mixing parameter controlling the weights of the original query and relevance model for RM3 runs. & 0.5 \\ \hline
\end{tabular}
\caption{Parameter settings for the entity linking procedure and retrieval model}
\label{table.parameters}
\end{table}

The various parameters required for our approach, along with their meanings and values are shown in Table \ref{table.parameters}. 

We sweep across values of $\lambda$ at intervals of $0.1$ to investigate how much weight should be given to the entity model. The results of these sweeps are shown in Figure \ref{figure.sweeps-ql} and discussed further in Section \ref{section.results}.

For this work, we set $k$ and $n$ heuristically. In principle, both parameters need not be limited beyond the length of the document and size of the corpus respectively; however, this would increase computation time significantly, so we have opted to set them to the specified values.

\section{Results}\label{section.results}

\begin{table}[htbp]
\centering
\begin{tabular}{|c|l|c|c|} \hline
& {\bf Run} & {\bf $\lambda$} & {\bf MAP} \\ \hline
\multirow{2}{*}{Robust} & {\it baseline-ql} & -- & 0.2183 \\ \cline{2-4}
%& {\it baseline-rm3} & -- & 0.2548 \\ \cline{2-4}
& {\it kb-ql} & 0.9 & {\bf 0.2275} \\ \hline \hline %\cline{2-4}
%& {\it kb-rm3} & & \\ \hline \hline
\multirow{2}{*}{AP} & {\it baseline-ql} & -- & 0.2346 \\ \cline{2-4}
%& {\it baseline-rm3} & -- & 0.2653 \\ \cline{2-4}
& {\it kb-ql} & 0.9 & {\bf 0.2515} \\ \hline %\cline{2-4}
%& {\it kb-rm3} & 0.8 & 0.2665 \\ \hline
\end{tabular}
\caption{The top-scoring knowledge base runs and baselines by mean average precision (MAP). $\lambda$ is specified for knowledge base runs. Bolded values indicate statistical significance compared to the baseline.}
\label{table.performance}
\end{table}

\begin{figure}
\centering
\includegraphics[width=\columnwidth]{figures/sweep-ql.pdf}
\caption{Sweeps over values of $\lambda$ for robust (red) and AP (blue) runs.}
\label{figure.sweeps-ql}
\end{figure}

\begin{comment}
\begin{figure}
\centering
\includegraphics[width=\columnwidth]{figures/sweep-rm3.pdf}
\caption{Sweeps over values of $\lambda$ for robust (red) and AP (blue) RM3 runs.}
\label{figure.sweeps-rm3}
\end{figure}
\end{comment}

Retrieval performance of the top-scoring knowledge base runs and baselines are shown in Table \ref{table.performance}. Bolded mean average precision (MAP) scores are greater than their corresponding baseline (e.g. \textit{kb-ql} compared to \textit{baseline-ql}) with statistical significance at $p < 0.001$ using a paired t-test. Note that baselines correspond to $\lambda = 0.0$. 

Though Table \ref{table.performance} shows only the top-scoring values of $\lambda$, performance for all knowledge base runs improved over the baseline for values of $0.0 < \lambda < 1.0$, as shown in Figure \ref{figure.sweeps-ql}. All improvements were statistically significant with at least $p < 0.05$.

% Paragraph about RM3 results...

\section{Conclusions}\label{section.conclusions}

The results indicate that our approach for constructing knowledge base links between documents and Wikipedia produces useful data for document retrieval purposes. Our simple document expansion model that incorporates these links performs well compared to a query likelihood baseline. These outcomes support our argument that a ``bag of links'' to a knowledge base can provide helpful information for a document retrieval task. Our proposed method using standard information retrieval techniques to build these links is efficient compared to usual entity linking and wikification systems and can be accomplished without the need for complex natural language processing.

In this paper, we have limited ourselves to using only knowledge base description text. However, knowledge base links provide a great deal more information. Future work may benefit from harnessing this knowledge base data such as hyperlink graphs and entity categories. Since our retrieval model performs \textit{document} expansion, we also plan to investigate its utility when paired with \textit{query} expansion techniques that employ knowledge base links.

\section{Acknowledgments}\label{section.acknowledgments}
This work was supported in part by the US National Science Foundation under Grant No. [blind]. Any opinions, findings, conclusions, or recommendations expressed are those of the authors and do not necessarily reflect the views of the National Science Foundation.


\bibliographystyle{abbrv}
\bibliography{references}  




\end{document}
